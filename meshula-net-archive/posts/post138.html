<!DOCTYPE html>
<html id="home" lang="en">
<head>
<meta charset=UTF-8" />
<!-- disable iPhone inital scale --> 
<meta name="viewport" content="width=device-width; initial-scale=1.0" /> <link rel="shortcut icon" href="favicon.ico">  
<!--[if lt IE 9]> 
 <!-- html5.js for IE less than 9 --> 
	<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
 <!-- css3-mediaqueries.js for IE less than 9 --> 
	<script src="http://css3-mediaqueries-js.googlecode.com/svn/trunk/css3-mediaqueries.js"></script>
<![endif]--> 
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-38190740-1']); _gaq.push(['_trackPageview']);
 (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
   ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
   var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })();
</script>
<link rel="stylesheet" href="../css/reset.css" type="text/css" />
<link rel="stylesheet" href="../css/isotype-style.css" type="text/css" media="screen" /> 
<link rel="stylesheet" href="../css/standard.css" type="text/css" />
<link rel="stylesheet" href="../css/buttons.css" type="text/css" /> 
<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Aclonica:regular" type="text/css" /> 
<TITLE>
Siggraph 1998
</TITLE></HEAD>
<BODY>
<div id="pagewrap">
<header id="header">
 <hgroup><h1 id="site-logo">Spaces Between</h1></hgroup>
</header>
<DIV id="articleHeader">
<H3 class='entry-date'>2007-11-10 18:08:21</h3>
<H1 class="title">Siggraph 1998</H1>
</DIV>
<div id="content">
<article class="post">
Siggraph 1998 was an extraordinary conference. This year saw more than its fair share of advances and seminal work that would come to bear fruit years later. This is my short list of most-interesting papers from Siggraph 1998. These papers either advance the art in a field that I am particularly interested in such as character animation, procedural modeling, or high quality lighting, or simply catch my fancy. The numbers refer to the chapter index in the paper proceedings. I have tried to link the project website; if there isn’t one, then the principal researcher’s website; if not that, then a pdf of the paper. Here they are, in order. <a href="http://www.cs.ucla.edu/~dt/papers/siggraph98/siggraph98.pdf">NeuroAnimator: Fast Neural Network Emulation and Control of Physics-Based Models</a>, <a href="http://research.nokia.com/people/radek_grzeszczuk/index.html">Radek Grzeszczuk</a>, <a href="http://www.cs.ucla.edu/~dt/">Demetri Terzopoulos</a>, <a href="http://www.cs.toronto.edu/~hinton/">Geoffrey Hinton</a>, pp. 9-20. This system couples a back-propagation in time algorithm to a set of muscle type actuators on a simple physics rig. Hinton popularized the back-propagation algorithm, and Terzopoulos' lab has been pushing this sort of procedural synthesis or years. I like it because it harkens back to my work in neural control of animation, a field which is only coming into its own today. <a href="http://www.cs.princeton.edu/gfx/pubs/Funkhouser_1998_ABT/index.php">A Beam Tracing Approach to Acoustic Modeling for Interactive Virtual Environments</a>, <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>, Ingrid Carlbom, Gary Elko, <a href="http://www.research.ibm.com/people/g/gpingali/">Gopal Pingali</a>, Mohan Sondhi, Jim West, pp. 21-32. This paper is a benchmark for interactive audio in immersive environments. The beam tracing approach is sometimes referred to in the generation of potentially visible sets for rendering acceleration. <a href="http://www.cs.wisc.edu/graphics/Papers/Gleicher/California/retarget-preprint.pdf">Retargetting Motion to New Characters</a>, <a href="http://pages.cs.wisc.edu/~gleicher/">Michael Gleicher</a>, pp. 33-42. This is an early and convincing example of retargetting animations from one rig to another. Gleicher solved some interesting problems that allow highly dimorphic rigs to share animation. There has been much work since on this problem, but aside from Cohen's work on space-time optimization, few solutions to this problem were previously known. <a href="http://www.cs.cmu.edu/~baraff/papers/sig98.pdf">Large Steps in Cloth Simulation</a>, <a href="http://www.cs.cmu.edu/~baraff/">David Baraff</a>, <a href="http://www.cs.cmu.edu/~aw/">Andrew Witkin</a>, pp. 43-54. Another ground breaking paper - this paper introduced constrained simulation with damping in an implicit integration formulation that allowed for large time steps to be taken yet remain stable. Descendants of this approach are now de rigeur for advanced real time cloth simulations in games. <a href="http://plenoptic.com/uw/makingfaces.pdf">Making Faces</a>, <a href="research.microsoft.com/users/bguenter/">Brian Guenter</a>, <a href="http://www.cs.wustl.edu/~cmg/">Cindy Grimm</a>, <a href="http://plenoptic.com/">Daniel Wood</a>, <a href="research.microsoft.com/users/malvar/">Henrique Malvar</a>, Fredrick Pighin, pp. 55-66. This work established the currently dominant methodology for facial motion capture. Shout out to my co-worker Fredrick! <a href="http://meshula.net/wordpress/wp-admin/Subdivision%20Surfaces%20in%20Character%20Animation">Subdivision Surfaces in Character Animation</a>, <a href="http://graphics.pixar.com/indexAuthorDeRose.html">Tony DeRose</a>, <a href="http://graphics.pixar.com/indexAuthorKass.html">Michael Kass</a>, Tien Truong, pp. 85-94. This paper marked the movement of film rendering technology towards Catmull-Clark surfaces. This paper demonstrated solutions to some hard problems such as good fillets between patches, deformation, and evaluative methods suitable for shaders to chew. Geri's Game showcased the technology, and it has featured in all Pixar films since. <a href="http://graphics.stanford.edu/papers/parallel_api/parallel_api.pdf">The Design of a Parallel Graphics Interface</a>, <a href="http://graphics.stanford.edu/~homan/">Homan Igehy</a>, Gordon Stoll, <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a>, pp. 141-150. An early framework for realtime parallel rendering. This paper showed the use of barriers and syncs as OpenGL extensions to allow multiple processors to render to a single framebuffer context. There are many similarities between this structure and what happens in parallel rendering engines such as Capcom's MT, and behind the scenes in modern graphics processors. <a href="http://www.cs.virginia.edu/~gfx/Courses/2002/BigData/papers/Texturing/Clipmap.pdf">The Clipmap: A Virtual Mipmap</a>, Christopher C. Tanner, Christopher J. Migdal, Michael T. Jones, pp. 151-158. Clipmaps are a method of level of detail management that allows interactive rendering of textures that are many times larger than available physical memory. As near as I can tell, id's megatextures are a variation on clipmaps, although debate seems passionate that they are the same, or that they aren't. <a href="http://www.debevec.org/Research/IBL/debevec-siggraph98.pdf">Rendering Synthetic Objects into Real Scenes: Bridging Traditional and Image-based Graphics with Global Illumination and High Dynamic Range Photography</a>, <a href="http://www.debevec.org/">Paul Debevec</a>, pp. 189-198. This paper is significant in that it has the largest disparity in Siggraph history of length of title versus number of authors. This paper introduced methods of illuminating synthetic objects with real light data, in high dynamic range. Debevec called this technique a light-based model, now we call it image based lighting, which is far less ambiguous. Debevec continues to innovate in this field. <a href="http://research.microsoft.com/research/pubs/view.aspx?type=Publication&amp;id=227">Visibility Sorting and Compositing without Splitting for Image Layer Decompositions</a>, <a href="http://research.microsoft.com/~johnsny/">John Snyder</a>, <a href="http://www.jedwork.com/jed/">Jed Lengyel</a>, pp. 219-230. I feel this is a largely overlooked, but highly signficant paper. This paper lays out the architecture for a composition engine very similar in intent to what I describe as a submission engine. Images are broken down in depth, and rendered to an accumulation buffer with layered processing yielding highly controllable and good looking results for such difficult problems as depth of field, motion blur, and parallel rendering. Both <a href="http://www.team-ico.net/sotc/index.html">Shadows of the Colossus</a> and <a href="http://meshula.net/wordpress/?p=124">Lost Planet</a> use these principles. <a href="http://grail.cs.washington.edu/projects/ldi/ldi.pdf">Layered Depth Images</a>, <a href="http://www.cs.washington.edu/homes/shade/">Jonathan Shade</a>, <a href="http://hillbilly.deas.harvard.edu/~sjg/">Steven Gortler</a>, <a href="http://graphics.stanford.edu/~lhe/">Li-wei He</a>, <a href="http://www.research.microsoft.com/research/vision/szeliski/">Richard Szeliski</a>, pp. 231-242. This paper extends the concept of depth sprites to layered depth images, where the sprites' depth displacement is warped to minimize distortion. There is a demonstration available on the <a href="http://grail.cs.washington.edu/projects/ldi/">project page</a>. <a href="http://graphics.stanford.edu/papers/ecosys/ecosys.pdf">Realistic Modeling and Rendering of Plant Ecosystems</a>, <a href="http://simsrv.cs.uni-magdeburg.de/~deussen/">Oliver Deussen</a>, <a href="http://graphics.stanford.edu/~hanrahan">Pat Hanrahan</a>, <a href="http://i31www.ira.uka.de/~linter/">Bernd Lintermann</a>, <a href="http://www.cpsc.ucalgary.ca/~mech/">Radomir Mech</a>, <a href="http://graphics.stanford.edu/~mmp">Matt Pharr</a>, <a href="http://www.cpsc.ucalgary.ca/~pwp">Przemyslaw Prusinkiewicz</a>, pp. 275-286. This paper laid out a method for generating statistical maps of an ecosystem that can be used to generate realistic vegetation on terrain. Modern programs such as Vue, and even games, such Relic's Company of Heroes use this technique to great effect. Efficient Simulation of Light Transport in Scenes with Participating Media using Photon Maps, <a href="http://graphics.ucsd.edu/~henrik/">Henrik Wann Jensen</a>, <a href="http://www.gk.dtu.dk/~per/">Per H. Christensen</a>, pp. 311-320. This paper introduced a new method of deriving a radiance estimate from the photons in a photon map. The whole photon mapping for global illumination calculation craze started here. <a href="http://www.dgp.toronto.edu/people/stam/reality/Research/pdf/sig98.pdf">Exact Evaluation of Catmull-Clark Subdivison Surfaces At Arbitrary Parameter Values</a>, <a href="http://www.dgp.toronto.edu/people/stam/">Jos Stam</a>, pp. 395-404. An influential paper highly referenced by people implementing subdivision surfaces using geometry shaders. <a href="http://grail.cs.washington.edu/pub/papers/Wong98.pdf">Computer-Generated Floral Ornament</a>, Michael T. Wong, Douglas E. Zongker, <a href="http://salesin.cs.washington.edu/">David H. Salesin</a>, pp. 423-434. Really cool method for iteratively generating decorative illuminations for book pages using pruned L-Systems. <a href="http://www.cs.northwestern.edu/~ago820/SIG98/gooch98.pdf">A Non-Realistic Lighting Model for Automatic Technical Illustration</a>, <a href="http://www.cs.northwestern.edu/~ago820/">Amy Gooch</a>, <a href="http://www.cs.northwestern.edu/~bgooch/">Bruce Gooch</a>, <a href="http://www.cs.utah.edu/~shirley/">Peter Shirley</a>, <a href="http://www.cs.utah.edu/~cohen/">Elaine Cohen</a>, pp. 447-452. This paper introduces the now well-known lighting model named Gooch Lighting.
</article>
</div>
<div id="tags">
CG/siggraph/1998</tags>

<footer id="footer"> 
	<p>Content by Nick Porcino (c) 1990-2011</p> 
</footer> 
	<!-- /#footer --> 
</div>

</BODY>
</HTML>
