<!DOCTYPE html>
<html id="home" lang="en">
<head>
<meta charset=UTF-8" />
<!-- disable iPhone inital scale --> 
<meta name="viewport" content="width=device-width; initial-scale=1.0" /> <link rel="shortcut icon" href="favicon.ico">  
<!--[if lt IE 9]> 
 <!-- html5.js for IE less than 9 --> 
	<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
 <!-- css3-mediaqueries.js for IE less than 9 --> 
	<script src="http://css3-mediaqueries-js.googlecode.com/svn/trunk/css3-mediaqueries.js"></script>
<![endif]--> 
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-38190740-1']); _gaq.push(['_trackPageview']);
 (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
   ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
   var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })();
</script>
<link rel="stylesheet" href="../css/reset.css" type="text/css" />
<link rel="stylesheet" href="../css/isotype-style.css" type="text/css" media="screen" /> 
<link rel="stylesheet" href="../css/standard.css" type="text/css" />
<link rel="stylesheet" href="../css/buttons.css" type="text/css" /> 
<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Aclonica:regular" type="text/css" /> 
<TITLE>
Rendering Engines
</TITLE></HEAD>
<BODY>
<div id="pagewrap">
<header id="header">
 <hgroup><h1 id="site-logo">Spaces Between</h1></hgroup>
</header>
<DIV id="articleHeader">
<H3 class='entry-date'>2007-09-08 15:24:52</h3>
<H1 class="title">Rendering Engines</H1>
</DIV>
<div id="content">
<article class="post">
<h3>En Plein Air</h3> <P>The last few years have seen an amazing improvement in the fundamentals of shading. We could summarize these improvements in general as reduction of artifacts and richness of rendering. Reduction of artifacts has improved through tesselation, filtering, and depth and transparency rendering. Richness has increased through higher geometry and texture throughput, and increases in shader program length allowing for a dramatic increase in the number of lights that can be computed. Shading is fundamentally concerned with the appearances of surfaces. </p> <h3>Moving beyond Surfaces</h3> <P> There's a completely different way of looking at the rendering of a scene. This method is common in landscape painting and matte painting in film. It is the notion of painting the air between the surfaces instead of the surfaces themselves. This technique became well known with the advent of the <em><a href="http://en.wikipedia.org/wiki/En_plein_air">en plein air</a></em> painters who advocated taking paint and canvas outside to paint from nature. Amusingly, this advance in painting was brought about by another technological revolution: the availability of paint in tubes supplanting the previous paradigm of artists mixing paints from powders, oils, and eggwhites! </p><P> The values of the surfaces themselves are not represented in these paintings, but rather the interaction of light with the intervening medium. As long as rendering technologies remain focused on surfaces, these well understood properties of beautiful images can only be indirectly approximated, using imperfect tricks such as adding a fog term to a surface shader. </p><P> A powerful compositing pipeline will be required to pull off a real time engine which can render participating media with light. Multiple layers must be individually rendered, with specific post processing between every pass. Partitioning the scene in depth, and the management of techniques such as scrims and a great variety of full screen post processes must be mastered. Avoiding artifacts between layers is a challenge here. </p><P> <img src="../../posts/images/enPleinAir.jpg" border="0" /> </p><P> Dan Curry talks about rendering with light instead of surfaces roughly half way through a fxguide podcast, available <a href="http://www.fxguide.com/article410.html">here</a>. </p> <h3>The Four S's of Rendering</h3> <P>Next, I identify the four modern paradigms for rendering engines, and draw a conclusion vis a vis how to approach next generation rendering hardware from an application/game programming standpoint.</p> <P>In quick summary, the four paradigms are:</p> <ol> <li>State Management Libraries</li> <li>Scene Management Libraries</li> <li>Shader Systems</li> <li>Submission Engines</li> </ol> <BR> <h3>State Management Libraries</h3> <BR> <P>State management APIs abstract an idealized model of the hardware as a state machine, and expose the management of that virtual hardware to the graphics programmer. Some of the earliest rendering APIs such as OpenGL are in this category. DirectX is another example of a state management API.</p> <P>It is a stretch to represent a state management library as a rendering engine, but a survey of the hundreds of render engines on the internet shows that a good proportion of them are state management libraries.</p> <BR> <h3>Scene Management Libraries</h3> <BR> <P>Scene management engines are sometimes called retained mode renderers, although this term is falling out of favor. Early realtime APIs such as RenderMorphics were retained mode. OpenInventor heavily inspired this line of development, with its notions of transformational hierarchy.</p> <P>Several modern render engines such as Ogre fall into this category. These engines are the most intrusive into your application program, forcing you to either adopt their scene representation, or to wrap the scene representation in a manager that feeds the underlying scene representation. These systems often attempt to provide extensibility or flexibility through a plugins system, whereby a base node or manager such as a shadow manager allow overriding through subclassing or callbacks.</p> <P>The pitfall here is that in general, these kinds of systems are only extensible through introducing complexity. More nodes and managers must be introduced, and then the interactions and marshalling of existing nodes and managers must be accomplished through delegation, spoofing, or rewriting the core systems.</p> <BR> <h3>Shader Systems</h3> <BR> <P>A scene is described as a light transport problem, as formulated by Kajiya in 1986 (Kajiya, J. T. The rendering equation. Computer Graphics 20, 3. Aug. 1986, 143-149). There are three categories of shader defined.</p> <ul> <li> <P><em><em>Light source shaders.</em> Calculate the lighting term, which is the color and intensity of light emitted from a source in a particular direction. </em></p> </li> <li> <P><em>Surface shaders.</em> Calculate the integral of the bidirectional reflectance function with the incoming light distribution.</p> </li> </ul> <ul> <li><em>Volume shaders.</em> Calculate scattering effects through participating media such as dusty air, salty water, fog, and smoke. Other participating media include translucent materials such as marble, skin, and plants.</li> </ul> <P>The predominant example of a shader based render engine is Renderman, although others exist; all are currently offline rendering systems.</p> <P>These systems are predicated on being able to fully describe a scene in a mathematically pure way. For example, a typical approach to introducing a new geometry file format to Renderman is to write a surface shader DSO to interpret the custom file.</p> <P>Optimization of such a scene must occur at a full scene level after all data has been submitted and all shaders run, since for example no geometry exists until all geometry shaders have run. The use of a shader system for real time rendering is therefore fundamentally intractable.</p> <BR> <h3>Submission Engines</h3> <BR> <P>Submission based engines combine features of scene management systems, and shader systems. Every frame, what to draw is presented anew to the render engine, in the form of a list of things to render, and composite operations. Things to render are bound tuples of lights to use, things to shade, and materials to shade with. A reference to a compiled submission list is also a possible thing to insert into a submission list. Composite operations are like fences in the rendering queue; typical operations are to target a particular framebuffer, to clear the depth buffer, or to perform a blend operation between existing framebuffers. Additionally, a submission list has ordering hints associated with objects in the list, such as pass information â€“ for example, a particular object may render on a sky dome layer that has a depth buffer clear operation invoked after the sky dome layer has rendered.</p> <P>Submission APIs wrap a state management API, but do not expose the state management API in any way to the programmer.</p> <P>Similarly to a shader based system, the things in the list are bound tuples bracketed with render start and end tokens. Similarly to a scene management system, a submission list may have submission lists within it, although there is no transformation hierarchy involved, nor is there persistent state change as might occur through a state management API. A well developed submission engine will provide a compile step, like an OpenGL display list. These precompiled submission lists potentially concatenate state information in a manner that allows fastest possible submission to the state management API. For example, on Xbox or X360, the compilation step bakes out a monolithic state block for the push buffers.</p> <P>What is fundamentally different from a shader system is that it is up to the submission engine to manage and bind shaders and hardware state as appropriate. What is fundamentally different from a scene management system is that the described scene is not managed via a persistent scene model visible to the programmer. In other words, there are no nodes to manage, and the scene is presented to the submission engine fresh every frame. The submission engine can cache, hint, and manage state internally to optimize the submissions.</p> <P>Many game companies use submission engines internally for high performance. I am not aware of any publicly available submission engines.</p> <h3>Conclusion</h3> <P>Today's biggest challenge in real time rendering is multiprocessing. Please refer to my article &ldquo;Gaming Graphics: Road to Revolution&rdquo; (<span class="small"><a title="ACM Queue vol. 2, no. 2 - April 2004" href="http://www.acmqueue.com/modules.php?name=Content&pa=showpage&pid=139&page=1" target="_blank">ACM Queue vol. 2, no. 2 - April 2004</a>)</span>, for a discussion of real time parallelism. I argue in that article that a modern render engine must implement efficient compositing and Sort Last parallelism to fully utilize modern parallel hardware. I feel that conclusion is more true now than ever, now that we know what challenges we face on the newest game consoles.</p> <P>Today, I advocate a Submission Engine approach for a rendering API, driving a composite/sort last optimizer, which in turn writes through to a state management library.</p> <P>28 June, 2008: I note that Johannes Spohr has built a submission engine parallel renderer for his <a href="http://www.plm.eecs.uni-kassel.de/plm/index.php?id=713">thesis work</a>. It's a good read, I was particularly interested in his observations on how his system scales.</P> <P> </p>
</article>
</div>
<div id="tags">
CG/games/rendering</tags>

<footer id="footer"> 
	<p>Content by Nick Porcino (c) 1990-2011</p> 
</footer> 
	<!-- /#footer --> 
</div>

</BODY>
</HTML>
